#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆæœ¬çš„é“¾æ¥æ·»åŠ è„šæœ¬
åŠŸèƒ½ï¼šä¸º sequences_cleaned.json ä¸­çš„è®°å½•æ·»åŠ  Linker å­—æ®µï¼Œå¹¶éªŒè¯é“¾æ¥æœ‰æ•ˆæ€§
"""
import json
import re
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass


@dataclass
class ProcessingStats:
    """å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
    total_records: int = 0
    records_with_existing_linker: int = 0
    records_without_page_name: int = 0
    linkers_added: int = 0
    valid_linkers: int = 0
    invalid_linkers: int = 0
    duplicated_page_names: int = 0


class LinkerProcessor:
    """é“¾æ¥å¤„ç†å™¨ç±»"""
    
    def __init__(self, json_path: str = "apidata/sequences_cleaned.json", 
                 posts_dir: str = "_posts", verbose: bool = False):
        self.json_path = Path(json_path)
        self.posts_dir = Path(posts_dir)
        self.verbose = verbose
        self.stats = ProcessingStats()
        self.invalid_linkers: List[Tuple[str, str, str]] = []  # (ID, page_name, reason)
        self.page_name_usage: Dict[str, List[str]] = {}  # page_name -> [ID1, ID2, ...]
        
    def log_verbose(self, message: str):
        """è¾“å‡ºè¯¦ç»†æ—¥å¿—"""
        if self.verbose:
            print(f"[DEBUG] {message}")
    
    def slugify(self, name: str) -> str:
        """
        å°†é¡µé¢åç§°è½¬æ¢ä¸ºç”¨äºæ–‡ä»¶åçš„slug
        
        è§„åˆ™ï¼š
        1. å»é™¤å‰åç©ºç™½å­—ç¬¦
        2. å°†ç©ºæ ¼å’Œè¿ç»­ç©ºç™½å­—ç¬¦æ›¿æ¢ä¸ºå•ä¸ªçŸ­æ¨ªçº¿'-'
        3. å°†ç‰¹æ®Šåˆ†éš”ç¬¦ï¼ˆem dash, en dash, æ–œæ , ä¸‹åˆ’çº¿ï¼‰æ›¿æ¢ä¸ºçŸ­æ¨ªçº¿
        4. ç§»é™¤é™¤å­—æ¯æ•°å­—ã€çŸ­æ¨ªçº¿ã€æ‹¬å·å¤–çš„å­—ç¬¦
        5. å‹ç¼©å¤šä¸ªçŸ­æ¨ªçº¿
        6. è¿”å›ä¸ä»¥çŸ­æ¨ªçº¿å¼€å¤´æˆ–ç»“å°¾çš„slug
        """
        slug = name.strip()
        self.log_verbose(f"Slugifying: '{name}' -> ç¬¬1æ­¥: '{slug}'")
        
        # è§„èŒƒåŒ–ç©ºæ ¼å’Œåˆ†éš”ç¬¦
        separator_pattern = r"[\s/Â·â€”â€“_]+"
        slug = re.sub(separator_pattern, "-", slug)
        self.log_verbose(f"Slugifying: ç¬¬2æ­¥(åˆ†éš”ç¬¦): '{slug}'")
        
        # ç§»é™¤ä¸éœ€è¦çš„æ ‡ç‚¹ç¬¦å·ï¼Œä½†ä¿ç•™æ‹¬å·
        slug = re.sub(r"[^A-Za-z0-9\-()]+", "", slug)
        self.log_verbose(f"Slugifying: ç¬¬3æ­¥(æ¸…ç†å­—ç¬¦): '{slug}'")
        
        # å‹ç¼©å¤šä¸ªçŸ­æ¨ªçº¿
        slug = re.sub(r"-{2,}", "-", slug)
        slug = slug.strip("-")
        self.log_verbose(f"Slugifying: æœ€ç»ˆç»“æœ: '{slug}'")
        
        return slug
    
    def validate_linker(self, linker_path: str) -> Tuple[bool, str]:
        """
        éªŒè¯é“¾æ¥æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            linker_path: é“¾æ¥è·¯å¾„ï¼Œå¦‚ '/_posts/ATP-aptamer.html'
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯åŸå› )
        """
        if not linker_path:
            return False, "é“¾æ¥ä¸ºç©º"
        
        if not linker_path.startswith('/_posts/'):
            return False, f"é“¾æ¥æ ¼å¼é”™è¯¯ï¼Œåº”ä»¥ '/_posts/' å¼€å¤´: {linker_path}"
        
        # æå–æ–‡ä»¶åï¼ˆå»é™¤ .html æ‰©å±•åï¼‰
        slug = Path(linker_path).stem
        
        # æ£€æŸ¥å¯¹åº”çš„ .md æˆ– .html æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        md_file = self.posts_dir / f"{slug}.md"
        html_file = self.posts_dir / f"{slug}.html"
        
        if md_file.exists():
            self.log_verbose(f"æ‰¾åˆ°å¯¹åº”çš„ .md æ–‡ä»¶: {md_file}")
            return True, ""
        elif html_file.exists():
            self.log_verbose(f"æ‰¾åˆ°å¯¹åº”çš„ .html æ–‡ä»¶: {html_file}")
            return True, ""
        else:
            return False, f"æ‰¾ä¸åˆ°å¯¹åº”çš„æºæ–‡ä»¶: {md_file} æˆ– {html_file}"
    
    def collect_page_name_usage(self, data: Dict) -> None:
        """æ”¶é›†é¡µé¢åç§°ä½¿ç”¨æƒ…å†µï¼Œæ£€æµ‹é‡å¤"""
        for record in data.get("Sheet1", []):
            page_name = record.get("Linker name(page name)")
            record_id = record.get("ID", "æœªçŸ¥ID")
            
            if page_name:
                if page_name not in self.page_name_usage:
                    self.page_name_usage[page_name] = []
                self.page_name_usage[page_name].append(record_id)
    
    def process_records(self, data: Dict, force_update: bool = False) -> bool:
        """
        å¤„ç†æ‰€æœ‰è®°å½•
        
        Args:
            data: JSONæ•°æ®
            force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°å·²å­˜åœ¨çš„é“¾æ¥
            
        Returns:
            bool: æ˜¯å¦æœ‰æ›´æ–°
        """
        if "Sheet1" not in data:
            raise KeyError("JSONæ•°æ®ä¸­ç¼ºå°‘ 'Sheet1' é”®")
        
        records = data["Sheet1"]
        self.stats.total_records = len(records)
        
        print(f"å¼€å§‹å¤„ç† {self.stats.total_records} æ¡è®°å½•...")
        
        # æ”¶é›†é¡µé¢åç§°ä½¿ç”¨æƒ…å†µ
        self.collect_page_name_usage(data)
        
        # ç»Ÿè®¡é‡å¤çš„é¡µé¢åç§°
        duplicated_names = {name: ids for name, ids in self.page_name_usage.items() 
                          if len(ids) > 1}
        self.stats.duplicated_page_names = len(duplicated_names)
        
        if duplicated_names:
            print(f"\nâš ï¸  å‘ç° {self.stats.duplicated_page_names} ä¸ªé‡å¤çš„é¡µé¢åç§°:")
            for name, ids in duplicated_names.items():
                print(f"  - '{name}' è¢«ä»¥ä¸‹è®°å½•ä½¿ç”¨: {', '.join(ids)}")
        
        updated = False
        
        for i, record in enumerate(records, 1):
            record_id = record.get("ID", f"è®°å½•_{i}")
            page_name = record.get("Linker name(page name)")
            existing_linker = record.get("Linker")
            
            self.log_verbose(f"\nå¤„ç†è®°å½• {i}/{self.stats.total_records}: {record_id}")
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰é“¾æ¥
            if existing_linker and not force_update:
                self.log_verbose(f"è®°å½•å·²æœ‰é“¾æ¥: {existing_linker}")
                self.stats.records_with_existing_linker += 1
                
                # éªŒè¯ç°æœ‰é“¾æ¥
                is_valid, error_reason = self.validate_linker(existing_linker)
                if is_valid:
                    self.stats.valid_linkers += 1
                else:
                    self.stats.invalid_linkers += 1
                    self.invalid_linkers.append((record_id, existing_linker, error_reason))
                    self.log_verbose(f"ç°æœ‰é“¾æ¥æ— æ•ˆ: {error_reason}")
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é¡µé¢åç§°
            if not page_name:
                self.log_verbose("ç¼ºå°‘é¡µé¢åç§°ï¼Œè·³è¿‡")
                self.stats.records_without_page_name += 1
                continue
            
            # ç”Ÿæˆæ–°é“¾æ¥
            slug = self.slugify(page_name)
            new_linker = f"/_posts/{slug}.html"
            
            self.log_verbose(f"ç”Ÿæˆæ–°é“¾æ¥: {new_linker}")
            
            # éªŒè¯æ–°é“¾æ¥
            is_valid, error_reason = self.validate_linker(new_linker)
            
            if is_valid:
                record["Linker"] = new_linker
                self.stats.linkers_added += 1
                self.stats.valid_linkers += 1
                updated = True
                self.log_verbose(f"âœ… æˆåŠŸæ·»åŠ æœ‰æ•ˆé“¾æ¥")
            else:
                self.stats.invalid_linkers += 1
                self.invalid_linkers.append((record_id, new_linker, error_reason))
                self.log_verbose(f"âŒ ç”Ÿæˆçš„é“¾æ¥æ— æ•ˆ: {error_reason}")
                
                # å³ä½¿é“¾æ¥æ— æ•ˆï¼Œä¹Ÿå¯ä»¥é€‰æ‹©æ·»åŠ ï¼ˆç”±è°ƒç”¨è€…å†³å®šï¼‰
                if force_update:
                    record["Linker"] = new_linker
                    self.stats.linkers_added += 1
                    updated = True
                    self.log_verbose("âš ï¸  å¼ºåˆ¶æ·»åŠ æ— æ•ˆé“¾æ¥")
        
        return updated
    
    def save_data(self, data: Dict) -> None:
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        with self.json_path.open("w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ° {self.json_path}")
    
    def print_statistics(self) -> None:
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ“Š å¤„ç†ç»Ÿè®¡ä¿¡æ¯")
        print("="*60)
        print(f"æ€»è®°å½•æ•°:              {self.stats.total_records}")
        print(f"å·²æœ‰é“¾æ¥çš„è®°å½•:        {self.stats.records_with_existing_linker}")
        print(f"ç¼ºå°‘é¡µé¢åç§°çš„è®°å½•:    {self.stats.records_without_page_name}")
        print(f"æ–°æ·»åŠ çš„é“¾æ¥:          {self.stats.linkers_added}")
        print(f"æœ‰æ•ˆé“¾æ¥æ•°:            {self.stats.valid_linkers}")
        print(f"æ— æ•ˆé“¾æ¥æ•°:            {self.stats.invalid_linkers}")
        print(f"é‡å¤é¡µé¢åç§°æ•°:        {self.stats.duplicated_page_names}")
        
        # è®¡ç®—ç™¾åˆ†æ¯”
        if self.stats.total_records > 0:
            valid_percentage = (self.stats.valid_linkers / self.stats.total_records) * 100
            print(f"é“¾æ¥æœ‰æ•ˆç‡:            {valid_percentage:.1f}%")
    
    def print_invalid_linkers(self, max_display: int = 20) -> None:
        """æ‰“å°æ— æ•ˆé“¾æ¥è¯¦æƒ…"""
        if not self.invalid_linkers:
            return
        
        print(f"\nâŒ æ— æ•ˆé“¾æ¥è¯¦æƒ… (æ˜¾ç¤ºå‰ {min(max_display, len(self.invalid_linkers))} ä¸ª):")
        print("-" * 80)
        for i, (record_id, linker, reason) in enumerate(self.invalid_linkers[:max_display]):
            print(f"{i+1:2d}. è®°å½•ID: {record_id}")
            print(f"    é“¾æ¥: {linker}")
            print(f"    åŸå› : {reason}")
            print()
        
        if len(self.invalid_linkers) > max_display:
            print(f"... è¿˜æœ‰ {len(self.invalid_linkers) - max_display} ä¸ªæ— æ•ˆé“¾æ¥æœªæ˜¾ç¤º")
    
    def run(self, force_update: bool = False, dry_run: bool = False) -> None:
        """
        è¿è¡Œå¤„ç†æµç¨‹
        
        Args:
            force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°å·²å­˜åœ¨çš„é“¾æ¥
            dry_run: æ˜¯å¦åªè¿›è¡Œæµ‹è¯•è¿è¡Œï¼ˆä¸ä¿å­˜æ–‡ä»¶ï¼‰
        """
        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        if not self.json_path.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {self.json_path}")
        
        if not self.posts_dir.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç›®å½•: {self.posts_dir}")
        
        print(f"ğŸ“‚ JSONæ–‡ä»¶è·¯å¾„: {self.json_path}")
        print(f"ğŸ“‚ Postsç›®å½•: {self.posts_dir}")
        print(f"ğŸ”§ å¼ºåˆ¶æ›´æ–°æ¨¡å¼: {'æ˜¯' if force_update else 'å¦'}")
        print(f"ğŸ§ª æµ‹è¯•è¿è¡Œæ¨¡å¼: {'æ˜¯' if dry_run else 'å¦'}")
        print(f"ğŸ“ è¯¦ç»†æ—¥å¿—: {'å¼€å¯' if self.verbose else 'å…³é—­'}")
        
        # åŠ è½½æ•°æ®
        print("\nğŸ“– åŠ è½½JSONæ•°æ®...")
        with self.json_path.open("r", encoding="utf-8") as f:
            data = json.load(f)
        
        # å¤„ç†è®°å½•
        updated = self.process_records(data, force_update)
        
        # ä¿å­˜æ•°æ®ï¼ˆå¦‚æœä¸æ˜¯dry runï¼‰
        if updated and not dry_run:
            self.save_data(data)
        elif dry_run:
            print("\nğŸ§ª æµ‹è¯•è¿è¡Œæ¨¡å¼ - æœªä¿å­˜æ›´æ”¹")
        elif not updated:
            print("\nâœ¨ æ²¡æœ‰éœ€è¦æ›´æ–°çš„è®°å½•")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        self.print_statistics()
        self.print_invalid_linkers()


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ä¸º sequences_cleaned.json æ·»åŠ å’ŒéªŒè¯ Linker å­—æ®µ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s                          # åŸºæœ¬è¿è¡Œ
  %(prog)s --verbose                # æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
  %(prog)s --force                  # å¼ºåˆ¶æ›´æ–°å·²å­˜åœ¨çš„é“¾æ¥
  %(prog)s --dry-run                # æµ‹è¯•è¿è¡Œï¼Œä¸ä¿å­˜æ–‡ä»¶
  %(prog)s --json-path path/to/data.json  # æŒ‡å®šJSONæ–‡ä»¶è·¯å¾„
        """
    )
    
    parser.add_argument(
        "--json-path", 
        default="apidata/sequences_cleaned.json",
        help="JSONæ•°æ®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: apidata/sequences_cleaned.json)"
    )
    parser.add_argument(
        "--posts-dir", 
        default="_posts",
        help="Postsç›®å½•è·¯å¾„ (é»˜è®¤: _posts)"
    )
    parser.add_argument(
        "--force", 
        action="store_true",
        help="å¼ºåˆ¶æ›´æ–°å·²å­˜åœ¨çš„é“¾æ¥"
    )
    parser.add_argument(
        "--dry-run", 
        action="store_true",
        help="æµ‹è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸ä¿å­˜ä»»ä½•æ›´æ”¹"
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯"
    )
    
    args = parser.parse_args()
    
    try:
        processor = LinkerProcessor(
            json_path=args.json_path,
            posts_dir=args.posts_dir,
            verbose=args.verbose
        )
        processor.run(
            force_update=args.force,
            dry_run=args.dry_run
        )
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main() 